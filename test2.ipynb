{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "class LogicFun:\n",
    "    ARGS_COUNT = None\n",
    "\n",
    "    def __init__(self, var_indexes, neg=False):\n",
    "        self.var_indexes = var_indexes\n",
    "        self.neg = neg\n",
    "\n",
    "    def boolean(self, inputs):\n",
    "        value = self._boolean(inputs)\n",
    "        return not value if self.neg else value\n",
    "\n",
    "    def real(self, inputs):\n",
    "        value = self._real(inputs)\n",
    "        return 1 - value if self.neg else value\n",
    "\n",
    "    def deriv(self, inputs):\n",
    "        value = self._deriv(inputs)\n",
    "        return -value if self.neg else value\n",
    "\n",
    "    def _boolean(self, inputs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _real(self, inputs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _deriv(self, inputs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class TrueFun(LogicFun):\n",
    "    ARGS_COUNT = 0\n",
    "    def _boolean(self, inputs): return True\n",
    "    def _real(self, inputs): return 1.0\n",
    "    def _deriv(self, inputs): return np.zeros_like(inputs)\n",
    "\n",
    "\n",
    "class IdentityFun(LogicFun):\n",
    "    ARGS_COUNT = 1\n",
    "    def _boolean(self, inputs): return inputs[self.var_indexes[0]]\n",
    "    def _real(self, inputs): return inputs[self.var_indexes[0]]\n",
    "    def _deriv(self, inputs):\n",
    "        deriv = np.zeros_like(inputs)\n",
    "        deriv[self.var_indexes[0]] = 1\n",
    "        return deriv\n",
    "\n",
    "\n",
    "class AndFun(LogicFun):\n",
    "    ARGS_COUNT = 2\n",
    "    def _boolean(self, inputs): return inputs[self.var_indexes[0]] and inputs[self.var_indexes[1]]\n",
    "    def _real(self, inputs): return inputs[self.var_indexes[0]] * inputs[self.var_indexes[1]]\n",
    "    def _deriv(self, inputs):\n",
    "        deriv = np.zeros_like(inputs)\n",
    "        deriv[self.var_indexes[0]] = inputs[self.var_indexes[1]]\n",
    "        deriv[self.var_indexes[1]] = inputs[self.var_indexes[0]]\n",
    "        return deriv\n",
    "\n",
    "\n",
    "class OrFun(LogicFun):\n",
    "    ARGS_COUNT = 2\n",
    "    def _boolean(self, inputs): return inputs[self.var_indexes[0]] or inputs[self.var_indexes[1]]\n",
    "    def _real(self, inputs): return inputs[self.var_indexes[0]] + inputs[self.var_indexes[1]] - inputs[self.var_indexes[0]] * inputs[self.var_indexes[1]]\n",
    "    def _deriv(self, inputs):\n",
    "        deriv = np.zeros_like(inputs)\n",
    "        deriv[self.var_indexes[0]] = 1 - inputs[self.var_indexes[1]]\n",
    "        deriv[self.var_indexes[1]] = 1 - inputs[self.var_indexes[0]]\n",
    "        return deriv\n",
    "    \n",
    "\n",
    "class Network:\n",
    "    def __init__(self, input_size, layers_sizes, connections_rate):\n",
    "        self.input_size = input_size\n",
    "        self.layers = self.__create_layers(input_size, layers_sizes, connections_rate)\n",
    "\n",
    "    def predict_boolean(self, inputs):\n",
    "        inputs = inputs > 0.5\n",
    "        outputs = [self.__propagate_boolean(input) for input in inputs]\n",
    "        return np.array(outputs)\n",
    "\n",
    "    def predict_real(self, inputs):\n",
    "        inputs = inputs.astype(np.float64)\n",
    "        outputs = [self.__propagate_real(input) for input in inputs]\n",
    "        return np.array(outputs)\n",
    "\n",
    "    def fit(self, inputs, outputs, epochs=1, learning_rate=0.01):\n",
    "        inputs, outputs = inputs.astype(np.float64), outputs.astype(np.float64)\n",
    "        for epoch in range(epochs):\n",
    "            self.__learn_epoch(inputs, outputs, learning_rate, epoch + 1)\n",
    "\n",
    "    def __propagate_boolean(self, input):\n",
    "        current_input = input\n",
    "        for layer in self.layers:\n",
    "            current_input = layer.propagate_boolean(current_input)\n",
    "        return current_input\n",
    "\n",
    "    def __propagate_real(self, input):\n",
    "        current_input = input\n",
    "        for layer in self.layers:\n",
    "            current_input = layer.propagate_real(current_input)\n",
    "        return current_input\n",
    "\n",
    "    def __learn_epoch(self, inputs, outputs, learning_rate, epoch_no):\n",
    "        shuffled_inputs, shuffled_outputs = self.__shuffle(inputs, outputs)\n",
    "        for input, output in zip(shuffled_inputs, shuffled_outputs):\n",
    "            self.__learn_single(input, output, learning_rate)\n",
    "\n",
    "    def __learn_single(self, input, output, learning_rate):\n",
    "        prediction = self.__propagate_real(input)\n",
    "        gradients = self.__get_loss_deriv(prediction, output)\n",
    "        self.__backpropagate(gradients, learning_rate)\n",
    "\n",
    "    def __backpropagate(self, gradients, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            gradients = layer.backpropagate(gradients, learning_rate)\n",
    "\n",
    "    @staticmethod\n",
    "    def __shuffle(inputs, outputs):\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "        return inputs[indices], outputs[indices]\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_loss_deriv(prediction, target):\n",
    "        return 2 * (prediction - target)\n",
    "\n",
    "    @staticmethod\n",
    "    def __create_layers(input_size, layers_sizes, connections_rate):\n",
    "        layers = []\n",
    "        all_sizes = [input_size, *layers_sizes]\n",
    "        for input_size, gates_count in zip(all_sizes, all_sizes[1:]):\n",
    "            layer = Layer(gates_count, input_size, connections_rate)\n",
    "            layers.append(layer)\n",
    "        return layers\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, size, input_size, connections_rate):\n",
    "        self.size = size\n",
    "        self.input_size = input_size\n",
    "        self.connections_rate = connections_rate\n",
    "        self.gates = [Gate(input_size, connections_rate) for _ in range(size)]\n",
    "\n",
    "    def propagate_boolean(self, input):\n",
    "        return np.array([gate.propagate_boolean(input) for gate in self.gates])\n",
    "\n",
    "    def propagate_real(self, input):\n",
    "        return np.array([gate.propagate_real(input) for gate in self.gates])\n",
    "\n",
    "    def backpropagate(self, gradient, learning_rate):\n",
    "        next_gradients = np.zeros((self.size, self.input_size), dtype=np.float64)\n",
    "        for i, (gate, gradient_elem) in enumerate(zip(self.gates, gradient)):\n",
    "            next_gradients[i, :] = gate.backpropagate(gradient_elem, learning_rate)\n",
    "        return np.sum(next_gradients, axis=0)\n",
    "\n",
    "\n",
    "class Gate:\n",
    "    FUNCTIONS = [TrueFun, IdentityFun, AndFun, OrFun]\n",
    "\n",
    "    def __init__(self, input_size, connections_rate):\n",
    "        self.input_size = input_size\n",
    "        self.connections_rate = connections_rate\n",
    "        self.funs = self.__create_all_functions_variants()\n",
    "        self.weights = np.random.randn(len(self.funs))\n",
    "        self.__input = None\n",
    "        self.__funs_results = None\n",
    "\n",
    "    def propagate_boolean(self, input):\n",
    "        max_weight_idx = np.argmax(self.weights)\n",
    "        fun = self.funs[max_weight_idx]\n",
    "        return fun.boolean(input)\n",
    "\n",
    "    def propagate_real(self, input):\n",
    "        funs_results = np.array([fun.real(input) for fun in self.funs])\n",
    "        soft_weights = self.__softmax(self.weights)\n",
    "        self.__input = input\n",
    "        self.__funs_results = funs_results\n",
    "        return soft_weights @ funs_results\n",
    "\n",
    "    def backpropagate(self, gradient, learning_rate):\n",
    "        next_gradient = self.__get_next_gradient(gradient)\n",
    "        self.__update_weights(gradient, learning_rate)\n",
    "        return next_gradient\n",
    "\n",
    "    def __get_next_gradient(self, gradient):\n",
    "        derivs = np.column_stack([fun.deriv(self.__input) for fun in self.funs])\n",
    "        derivs = derivs * self.__softmax(self.weights)\n",
    "        derivs = np.sum(derivs, axis=1)\n",
    "        return gradient * derivs\n",
    "\n",
    "    def __update_weights(self, gradient, learning_rate):\n",
    "        self.weights -= gradient * self.__funs_results * learning_rate\n",
    "\n",
    "    @staticmethod\n",
    "    def __softmax(x):\n",
    "        x = x - np.max(x)\n",
    "        e = np.exp(x)\n",
    "        s = np.sum(e)\n",
    "        return e / s if s != 0 else np.zeros_like(e)\n",
    "\n",
    "    def __create_all_functions_variants(self):\n",
    "        all_variants = []\n",
    "        for func_cls in self.FUNCTIONS:\n",
    "            func_variants = self.__create_function_variants(func_cls)\n",
    "            all_variants.extend(func_variants)\n",
    "        return all_variants\n",
    "\n",
    "    def __create_function_variants(self, func_cls):\n",
    "        vars_combinations = list(combinations(range(self.input_size), func_cls.ARGS_COUNT))\n",
    "        vars_combinations = random.sample(vars_combinations, k=min(self.connections_rate, len(vars_combinations)))\n",
    "        return [func_cls(vars_combination, neg) for vars_combination in vars_combinations for neg in [True, False]]\n",
    "    \n",
    "\n",
    "def get_accuracy(prediction, target):\n",
    "    prediction, target = prediction > 0.5, target > 0.5\n",
    "    correct_count = np.sum(np.all(prediction == target, axis=1))\n",
    "    total_count = len(target)\n",
    "    return correct_count / total_count if total_count != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets.mnist import load_data as load_data_MNIST\n",
    "from einops import rearrange\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data_MNIST()\n",
    "\n",
    "x_train = rearrange(x_train, 'b h w -> b (h w)')\n",
    "x_test = rearrange(x_test, 'b h w -> b (h w)')\n",
    "\n",
    "features = x_test > 100\n",
    "outputs = (y_test == 5).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network(784, [40, 50, 50, 40, 1], connections_rate=5)\n",
    "network.fit(features, outputs, epochs=1, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = network.predict_real(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9108\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(predictions, outputs)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
